{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸŽ¬ VideoGenerator3000 - Google Colab Edition\n",
        "\n",
        "ÐŸÐ¾Ð»Ð½Ð°Ñ Ð²ÐµÑ€ÑÐ¸Ñ Telegram Ð±Ð¾Ñ‚Ð° Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð²Ð¸Ð´ÐµÐ¾ Ñ Ð±Ð°Ð·Ð¾Ð¹ Ð´Ð°Ð½Ð½Ñ‹Ñ…, Ð¾Ñ‡ÐµÑ€ÐµÐ´ÑÐ¼Ð¸ Ð·Ð°Ð´Ð°Ñ‡ Ð¸ Ð²ÑÐµÐ¼Ð¸ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑÐ¼Ð¸.\n",
        "\n",
        "## âš ï¸ Ð’Ð°Ð¶Ð½Ñ‹Ðµ Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ñ Colab:\n",
        "- Ð¡ÐµÑÑÐ¸Ñ Ð¶Ð¸Ð²ÐµÑ‚ 12-24 Ñ‡Ð°ÑÐ°\n",
        "- Ð’ÑÐµ Ð´Ð°Ð½Ð½Ñ‹Ðµ ÑƒÐ´Ð°Ð»ÑÑŽÑ‚ÑÑ Ð¿Ñ€Ð¸ Ð¿ÐµÑ€ÐµÐ·Ð°Ð¿ÑƒÑÐºÐµ\n",
        "- ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð½Ñ‹Ðµ Ñ€ÐµÑÑƒÑ€ÑÑ‹ CPU/RAM\n",
        "- ÐÐµÑ‚ Ð¿Ð¾ÑÑ‚Ð¾ÑÐ½Ð½Ð¾Ð³Ð¾ IP\n",
        "\n",
        "## ðŸš€ Ð’Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸:\n",
        "- âœ… ÐŸÐ¾Ð»Ð½Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð²Ð¸Ð´ÐµÐ¾ Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Shorts (9:16)\n",
        "- âœ… Ð‘Ð°Ð·Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ… PostgreSQL\n",
        "- âœ… ÐžÑ‡ÐµÑ€ÐµÐ´Ð¸ Ð·Ð°Ð´Ð°Ñ‡ Celery + Redis\n",
        "- âœ… Ð¡ÐºÐ°Ñ‡Ð¸Ð²Ð°Ð½Ð¸Ðµ Ñ YouTube, TikTok Ð¸ Ð´Ñ€.\n",
        "- âœ… ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ ÑÑƒÐ±Ñ‚Ð¸Ñ‚Ñ€Ñ‹\n",
        "- âœ… Ð Ð°Ð·Ð¼Ñ‹Ñ‚Ñ‹Ð¹ Ñ„Ð¾Ð½\n",
        "- âœ… ÐÐ°Ñ€ÐµÐ·ÐºÐ° Ð½Ð° Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ñ‹\n",
        "- âœ… Ð˜Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ñ Ñ Google Drive\n"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“‹ Ð¨Ð°Ð³ 1: Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð½Ð°Ñ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ°\n",
        "\n",
        "Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð²ÑÐµ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ñ‹Ðµ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¸ Ð½Ð°ÑÑ‚Ñ€Ð°Ð¸Ð²Ð°ÐµÐ¼ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ðµ."
      ],
      "metadata": {
        "id": "step1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ÐšÐ»Ð¾Ð½Ð¸Ñ€ÑƒÐµÐ¼ Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ð¸Ð¹ Ñ GitHub\n",
        "print(\"ðŸ“¥ Cloning repository from GitHub...\")\n",
        "!git clone https://github.com/uiper123/VideoGenerator3000.git /content/VideoGenerator3000\n",
        "\n",
        "# ÐŸÐµÑ€ÐµÑ…Ð¾Ð´Ð¸Ð¼ Ð² Ð¿Ð°Ð¿ÐºÑƒ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°\n",
        "%cd /content/VideoGenerator3000\n",
        "\n",
        "# ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ñ‡Ñ‚Ð¾ ÑÐºÐ°Ñ‡Ð°Ð»Ð¾ÑÑŒ\n",
        "print(\"\\nðŸ“ Repository contents:\")\n",
        "!ls -la\n",
        "\n",
        "print(\"\\nâœ… Repository cloned successfully!\")"
      ],
      "metadata": {
        "id": "clone_repo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ ÑÐ¸ÑÑ‚ÐµÐ¼Ð½ÑƒÑŽ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÑƒ\n",
        "print(\"ðŸ”§ Running system setup...\")\n",
        "!python colab_setup_direct.py\n",
        "\n",
        "print(\"\\nâœ… System setup completed!\")"
      ],
      "metadata": {
        "id": "run_setup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“ Ð¨Ð°Ð³ 2: Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° ÐºÐ¾Ð´Ð° Ð±Ð¾Ñ‚Ð°\n",
        "\n",
        "Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ñ„Ð°Ð¹Ð»Ñ‹ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°. Ð•ÑÑ‚ÑŒ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ ÑÐ¿Ð¾ÑÐ¾Ð±Ð¾Ð²:"
      ],
      "metadata": {
        "id": "step2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ÐšÐ¾Ð¿Ð¸Ñ€ÑƒÐµÐ¼ Ñ„Ð°Ð¹Ð»Ñ‹ Ð¸Ð· Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ð¸Ñ Ð² Ñ€Ð°Ð±Ð¾Ñ‡ÑƒÑŽ Ð¿Ð°Ð¿ÐºÑƒ\n",
        "print(\"ðŸ“ Setting up project files...\")\n",
        "\n",
        "# ÐšÐ¾Ð¿Ð¸Ñ€ÑƒÐµÐ¼ Ð²ÑÐµ Ñ„Ð°Ð¹Ð»Ñ‹ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð° Ð² /content/videobot/\n",
        "!mkdir -p /content/videobot\n",
        "!cp -r /content/VideoGenerator3000/app /content/videobot/ 2>/dev/null || echo \"No app folder found\"\n",
        "!cp /content/VideoGenerator3000/*.py /content/videobot/ 2>/dev/null || echo \"No Python files in root\"\n",
        "!cp /content/VideoGenerator3000/requirements.txt /content/videobot/ 2>/dev/null || echo \"No requirements.txt\"\n",
        "!cp /content/VideoGenerator3000/.env /content/videobot/ 2>/dev/null || echo \"No .env file\"\n",
        "\n",
        "# Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¿Ð°Ð¿ÐºÐ¸\n",
        "!mkdir -p /content/videobot/temp\n",
        "!mkdir -p /content/videobot/logs\n",
        "!mkdir -p /content/videobot/fonts\n",
        "\n",
        "print(\"\\nðŸ“‹ Project structure:\")\n",
        "!ls -la /content/videobot/\n",
        "\n",
        "print(\"\\nâœ… Project files ready!\")"
      ],
      "metadata": {
        "id": "setup_project"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ð˜ÑÐ¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñƒ Ñ youtube_dl Ð² ÐºÐ¾Ð´Ðµ\n",
        "print(\"ðŸ”§ Fixing youtube_dl imports...\")\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# ÐÐ°Ð¹Ð´ÐµÐ¼ Ð²ÑÐµ Python Ñ„Ð°Ð¹Ð»Ñ‹ Ð² Ð¿Ñ€Ð¾ÐµÐºÑ‚Ðµ\n",
        "python_files = glob.glob('/content/videobot/**/*.py', recursive=True)\n",
        "python_files.extend(glob.glob('/content/videobot/*.py'))\n",
        "\n",
        "fixed_files = []\n",
        "for file_path in python_files:\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "        \n",
        "        # Ð•ÑÐ»Ð¸ ÐµÑÑ‚ÑŒ youtube_dl, Ð·Ð°Ð¼ÐµÐ½ÑÐµÐ¼ Ð½Ð° yt_dlp\n",
        "        if 'youtube_dl' in content:\n",
        "            print(f\"ðŸ”§ Fixing {file_path}\")\n",
        "            content = content.replace('import youtube_dl', 'import yt_dlp as youtube_dl')\n",
        "            content = content.replace('from youtube_dl', 'from yt_dlp')\n",
        "            \n",
        "            with open(file_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(content)\n",
        "            fixed_files.append(file_path)\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error processing {file_path}: {e}\")\n",
        "\n",
        "if fixed_files:\n",
        "    print(f\"\\nâœ… Fixed {len(fixed_files)} files:\")\n",
        "    for file in fixed_files:\n",
        "        print(f\"   - {file}\")\n",
        "else:\n",
        "    print(\"\\nâœ… No youtube_dl imports found to fix\")\n",
        "\n",
        "print(\"\\nâœ… Code fixes completed!\")"
      ],
      "metadata": {
        "id": "fix_imports"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð½Ñ‹Ðµ Ñ„Ð°Ð¹Ð»Ñ‹ Ð´Ð»Ñ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð° Ð¸ Ð´Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐ¸\n",
        "print(\"ðŸ”§ Creating enhanced monitoring tools...\")\n",
        "\n",
        "# 1. Google Drive Checker\n",
        "drive_checker_code = '''#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Google Drive Token Checker - Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚ Ñ€Ð°Ð±Ð¾Ñ‚Ð¾ÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ð¾ÑÑ‚ÑŒ Ñ‚Ð¾ÐºÐµÐ½Ð° Google Drive\n",
        "\"\"\"\n",
        "import os\n",
        "import pickle\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "try:\n",
        "    from google.auth.transport.requests import Request\n",
        "    from google.oauth2.credentials import Credentials\n",
        "    from google_auth_oauthlib.flow import InstalledAppFlow\n",
        "    from googleapiclient.discovery import build\n",
        "    from googleapiclient.errors import HttpError\n",
        "    GOOGLE_LIBS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    GOOGLE_LIBS_AVAILABLE = False\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class GoogleDriveChecker:\n",
        "    \"\"\"ÐšÐ»Ð°ÑÑ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ Google Drive Ñ‚Ð¾ÐºÐµÐ½Ð° Ð¸ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ\"\"\"\n",
        "    \n",
        "    def __init__(self, token_path: str = \"token.pickle\", credentials_path: str = \"google-credentials.json\"):\n",
        "        self.token_path = token_path\n",
        "        self.credentials_path = credentials_path\n",
        "        self.scopes = ['https://www.googleapis.com/auth/drive']\n",
        "    \n",
        "    def check_libraries(self) -> dict:\n",
        "        \"\"\"ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚ Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ðµ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ñ‹Ñ… Ð±Ð¸Ð±Ð»Ð¸Ð¾Ñ‚ÐµÐº\"\"\"\n",
        "        result = {\n",
        "            'status': 'success' if GOOGLE_LIBS_AVAILABLE else 'error',\n",
        "            'message': 'Google libraries available' if GOOGLE_LIBS_AVAILABLE else 'Google libraries not installed',\n",
        "            'libraries': GOOGLE_LIBS_AVAILABLE\n",
        "        }\n",
        "        \n",
        "        if not GOOGLE_LIBS_AVAILABLE:\n",
        "            result['fix'] = 'pip install google-api-python-client google-auth-httplib2 google-auth-oauthlib'\n",
        "        \n",
        "        return result\n",
        "    \n",
        "    def check_credentials_file(self) -> dict:\n",
        "        \"\"\"ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚ Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ðµ Ñ„Ð°Ð¹Ð»Ð° credentials\"\"\"\n",
        "        if not os.path.exists(self.credentials_path):\n",
        "            return {\n",
        "                'status': 'error',\n",
        "                'message': f'Credentials file not found: {self.credentials_path}',\n",
        "                'fix': 'Download credentials.json from Google Cloud Console'\n",
        "            }\n",
        "        \n",
        "        try:\n",
        "            with open(self.credentials_path, 'r') as f:\n",
        "                import json\n",
        "                creds_data = json.load(f)\n",
        "                \n",
        "            if 'installed' in creds_data or 'web' in creds_data:\n",
        "                return {\n",
        "                    'status': 'success',\n",
        "                    'message': f'Credentials file found and valid: {self.credentials_path}',\n",
        "                    'type': 'installed' if 'installed' in creds_data else 'web'\n",
        "                }\n",
        "            else:\n",
        "                return {\n",
        "                    'status': 'error',\n",
        "                    'message': 'Invalid credentials file format',\n",
        "                    'fix': 'Re-download credentials.json from Google Cloud Console'\n",
        "                }\n",
        "                \n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'status': 'error',\n",
        "                'message': f'Error reading credentials file: {e}',\n",
        "                'fix': 'Check credentials.json file format'\n",
        "            }\n",
        "    \n",
        "    def check_token_file(self) -> dict:\n",
        "        \"\"\"ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚ Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ðµ Ð¸ Ð²Ð°Ð»Ð¸Ð´Ð½Ð¾ÑÑ‚ÑŒ Ñ‚Ð¾ÐºÐµÐ½Ð°\"\"\"\n",
        "        if not os.path.exists(self.token_path):\n",
        "            return {\n",
        "                'status': 'warning',\n",
        "                'message': f'Token file not found: {self.token_path}',\n",
        "                'fix': 'Run OAuth flow to generate token'\n",
        "            }\n",
        "        \n",
        "        try:\n",
        "            with open(self.token_path, 'rb') as token:\n",
        "                creds = pickle.load(token)\n",
        "            \n",
        "            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð±Ð°Ð·Ð¾Ð²Ñ‹Ðµ ÑÐ²Ð¾Ð¹ÑÑ‚Ð²Ð° Ñ‚Ð¾ÐºÐµÐ½Ð°\n",
        "            token_info = {\n",
        "                'status': 'success',\n",
        "                'message': f'Token file found: {self.token_path}',\n",
        "                'valid': creds.valid if hasattr(creds, 'valid') else False,\n",
        "                'expired': creds.expired if hasattr(creds, 'expired') else True,\n",
        "                'token_uri': getattr(creds, 'token_uri', 'N/A'),\n",
        "                'scopes': getattr(creds, 'scopes', [])\n",
        "            }\n",
        "            \n",
        "            if hasattr(creds, 'expiry') and creds.expiry:\n",
        "                token_info['expiry'] = creds.expiry.isoformat()\n",
        "                token_info['expires_in_hours'] = (creds.expiry - datetime.utcnow()).total_seconds() / 3600\n",
        "            \n",
        "            return token_info\n",
        "                \n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'status': 'error',\n",
        "                'message': f'Error reading token file: {e}',\n",
        "                'fix': 'Delete token.pickle and re-run OAuth flow'\n",
        "            }\n",
        "    \n",
        "    def test_drive_connection(self) -> dict:\n",
        "        \"\"\"Ð¢ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÑ‚ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ðº Google Drive\"\"\"\n",
        "        if not GOOGLE_LIBS_AVAILABLE:\n",
        "            return {\n",
        "                'status': 'error',\n",
        "                'message': 'Google libraries not available',\n",
        "                'fix': 'Install required libraries first'\n",
        "            }\n",
        "        \n",
        "        try:\n",
        "            # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ñ‚Ð¾ÐºÐµÐ½\n",
        "            creds = None\n",
        "            if os.path.exists(self.token_path):\n",
        "                with open(self.token_path, 'rb') as token:\n",
        "                    creds = pickle.load(token)\n",
        "            \n",
        "            # Ð•ÑÐ»Ð¸ Ñ‚Ð¾ÐºÐµÐ½Ð° Ð½ÐµÑ‚ Ð¸Ð»Ð¸ Ð¾Ð½ Ð½ÐµÐ´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ‚ÐµÐ»ÐµÐ½, Ð¿Ñ‹Ñ‚Ð°ÐµÐ¼ÑÑ Ð¾Ð±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ\n",
        "            if not creds or not creds.valid:\n",
        "                if creds and creds.expired and creds.refresh_token:\n",
        "                    logger.info(\"Refreshing expired token...\")\n",
        "                    creds.refresh(Request())\n",
        "                else:\n",
        "                    return {\n",
        "                        'status': 'error',\n",
        "                        'message': 'No valid credentials available',\n",
        "                        'fix': 'Run OAuth flow to get new token'\n",
        "                    }\n",
        "            \n",
        "            # Ð¢ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ\n",
        "            service = build('drive', 'v3', credentials=creds)\n",
        "            \n",
        "            # ÐŸÑ€Ð¾ÑÑ‚Ð¾Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ\n",
        "            results = service.files().list(pageSize=1, fields=\"files(id, name)\").execute()\n",
        "            files = results.get('files', [])\n",
        "            \n",
        "            # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ðµ\n",
        "            about = service.about().get(fields=\"user\").execute()\n",
        "            user_info = about.get('user', {})\n",
        "            \n",
        "            return {\n",
        "                'status': 'success',\n",
        "                'message': 'Google Drive connection successful',\n",
        "                'user_email': user_info.get('emailAddress', 'N/A'),\n",
        "                'user_name': user_info.get('displayName', 'N/A'),\n",
        "                'files_accessible': len(files) > 0,\n",
        "                'test_time': datetime.now().isoformat()\n",
        "            }\n",
        "                \n",
        "        except HttpError as e:\n",
        "            return {\n",
        "                'status': 'error',\n",
        "                'message': f'Google Drive API error: {e}',\n",
        "                'error_code': getattr(e, 'resp', {}).get('status', 'unknown'),\n",
        "                'fix': 'Check API permissions and quotas'\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'status': 'error',\n",
        "                'message': f'Connection test failed: {e}',\n",
        "                'fix': 'Check credentials and network connection'\n",
        "            }\n",
        "    \n",
        "    def full_check(self) -> dict:\n",
        "        \"\"\"Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÑ‚ Ð¿Ð¾Ð»Ð½ÑƒÑŽ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÑƒ Google Drive Ð¸Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ð¸\"\"\"\n",
        "        logger.info(\"ðŸ” Starting full Google Drive check...\")\n",
        "        \n",
        "        results = {\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "            'libraries': self.check_libraries(),\n",
        "            'credentials_file': self.check_credentials_file(),\n",
        "            'token_file': self.check_token_file(),\n",
        "            'drive_connection': None,\n",
        "            'overall_status': 'unknown'\n",
        "        }\n",
        "        \n",
        "        # Ð¢ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐµÑÐ»Ð¸ Ð¿Ñ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰Ð¸Ðµ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ Ð¿Ñ€Ð¾ÑˆÐ»Ð¸\n",
        "        if (results['libraries']['status'] == 'success' and \n",
        "            results['credentials_file']['status'] == 'success'):\n",
        "            results['drive_connection'] = self.test_drive_connection()\n",
        "        else:\n",
        "            results['drive_connection'] = {\n",
        "                'status': 'skipped',\n",
        "                'message': 'Skipped due to previous errors'\n",
        "            }\n",
        "        \n",
        "        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð¾Ð±Ñ‰Ð¸Ð¹ ÑÑ‚Ð°Ñ‚ÑƒÑ\n",
        "        if results['drive_connection']['status'] == 'success':\n",
        "            results['overall_status'] = 'success'\n",
        "        elif any(r['status'] == 'error' for r in results.values() if isinstance(r, dict)):\n",
        "            results['overall_status'] = 'error'\n",
        "        else:\n",
        "            results['overall_status'] = 'warning'\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def format_check_results(self, results: dict) -> str:\n",
        "        \"\"\"Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€ÑƒÐµÑ‚ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ Ð´Ð»Ñ Ð²Ñ‹Ð²Ð¾Ð´Ð°\"\"\"\n",
        "        output = []\n",
        "        output.append(\"ðŸ” Google Drive Integration Check\")\n",
        "        output.append(\"=\" * 40)\n",
        "        \n",
        "        # Ð‘Ð¸Ð±Ð»Ð¸Ð¾Ñ‚ÐµÐºÐ¸\n",
        "        lib_status = \"âœ…\" if results['libraries']['status'] == 'success' else \"âŒ\"\n",
        "        output.append(f\"{lib_status} Libraries: {results['libraries']['message']}\")\n",
        "        if 'fix' in results['libraries']:\n",
        "            output.append(f\"   Fix: {results['libraries']['fix']}\")\n",
        "        \n",
        "        # Ð¤Ð°Ð¹Ð» credentials\n",
        "        cred_status = \"âœ…\" if results['credentials_file']['status'] == 'success' else \"âŒ\"\n",
        "        output.append(f\"{cred_status} Credentials: {results['credentials_file']['message']}\")\n",
        "        if 'fix' in results['credentials_file']:\n",
        "            output.append(f\"   Fix: {results['credentials_file']['fix']}\")\n",
        "        \n",
        "        # Ð¢Ð¾ÐºÐµÐ½\n",
        "        token_status = \"âœ…\" if results['token_file']['status'] == 'success' else (\"âš ï¸\" if results['token_file']['status'] == 'warning' else \"âŒ\")\n",
        "        output.append(f\"{token_status} Token: {results['token_file']['message']}\")\n",
        "        if 'valid' in results['token_file']:\n",
        "            output.append(f\"   Valid: {results['token_file']['valid']}\")\n",
        "            output.append(f\"   Expired: {results['token_file']['expired']}\")\n",
        "        if 'expires_in_hours' in results['token_file']:\n",
        "            hours = results['token_file']['expires_in_hours']\n",
        "            if hours > 0:\n",
        "                output.append(f\"   Expires in: {hours:.1f} hours\")\n",
        "            else:\n",
        "                output.append(f\"   Expired {abs(hours):.1f} hours ago\")\n",
        "        \n",
        "        # ÐŸÐ¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ðº Drive\n",
        "        if results['drive_connection']['status'] != 'skipped':\n",
        "            drive_status = \"âœ…\" if results['drive_connection']['status'] == 'success' else \"âŒ\"\n",
        "            output.append(f\"{drive_status} Drive Connection: {results['drive_connection']['message']}\")\n",
        "            if 'user_email' in results['drive_connection']:\n",
        "                output.append(f\"   User: {results['drive_connection']['user_email']}\")\n",
        "            if 'fix' in results['drive_connection']:\n",
        "                output.append(f\"   Fix: {results['drive_connection']['fix']}\")\n",
        "        \n",
        "        # ÐžÐ±Ñ‰Ð¸Ð¹ ÑÑ‚Ð°Ñ‚ÑƒÑ\n",
        "        overall_emoji = {\"success\": \"âœ…\", \"warning\": \"âš ï¸\", \"error\": \"âŒ\"}.get(results['overall_status'], \"â“\")\n",
        "        output.append(f\"\\n{overall_emoji} Overall Status: {results['overall_status'].upper()}\")\n",
        "        \n",
        "        return \"\\n\".join(output)\n",
        "'''\n",
        "\n",
        "with open('/content/videobot/google_drive_checker.py', 'w') as f:\n",
        "    f.write(drive_checker_code)\n",
        "\n",
        "print(\"âœ… Google Drive checker created\")\n",
        "\n",
        "# 2. Enhanced Worker Logger\n",
        "worker_logger_code = '''#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Enhanced Worker Logger - Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐµÑ‚ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð² Celery tasks\n",
        "\"\"\"\n",
        "import os\n",
        "import logging\n",
        "import sys\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "def get_worker_logs(lines: int = 50) -> str:\n",
        "    \"\"\"ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÑ‚ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ Ð»Ð¾Ð³Ð¸ worker'Ð¾Ð²\"\"\"\n",
        "    try:\n",
        "        log_file = Path(\"logs/worker.log\")\n",
        "        if not log_file.exists():\n",
        "            return \"âŒ Ð¤Ð°Ð¹Ð» Ð»Ð¾Ð³Ð¾Ð² worker'Ð¾Ð² Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½\"\n",
        "        \n",
        "        with open(log_file, 'r', encoding='utf-8') as f:\n",
        "            all_lines = f.readlines()\n",
        "            recent_lines = all_lines[-lines:] if len(all_lines) > lines else all_lines\n",
        "            \n",
        "        return ''.join(recent_lines)\n",
        "    \n",
        "    except Exception as e:\n",
        "        return f\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ñ‡Ñ‚ÐµÐ½Ð¸Ñ Ð»Ð¾Ð³Ð¾Ð²: {e}\"\n",
        "'''\n",
        "\n",
        "with open('/content/videobot/enhanced_worker_logger.py', 'w') as f:\n",
        "    f.write(worker_logger_code)\n",
        "\n",
        "print(\"âœ… Enhanced worker logger created\")\n",
        "\n",
        "# 3. Google Drive Fix Script\n",
        "drive_fix_code = '''#!/usr/bin/env python3\n",
        "import os\n",
        "import pickle\n",
        "import logging\n",
        "\n",
        "def fix_google_drive_service():\n",
        "    \"\"\"Ð˜ÑÐ¿Ñ€Ð°Ð²Ð»ÑÐµÑ‚ GoogleDriveService Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¾Ð½ Ð½Ðµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð» mock\"\"\"\n",
        "    print(\"ðŸ”§ Fixing Google Drive service...\")\n",
        "    \n",
        "    service_file = \"app/services/google_drive.py\"\n",
        "    \n",
        "    if not os.path.exists(service_file):\n",
        "        print(f\"âŒ File {service_file} not found\")\n",
        "        return False\n",
        "    \n",
        "    try:\n",
        "        with open(service_file, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "        \n",
        "        # Replace mock URLs with more informative ones\n",
        "        if \"mock.drive.url\" in content:\n",
        "            print(\"âš ï¸ Found mock code, fixing...\")\n",
        "            \n",
        "            content = content.replace(\n",
        "                '\"webViewLink\": \"https://mock.drive.url/file/view\"',\n",
        "                '\"webViewLink\": \"https://drive.google.com/file/d/mock_file_id/view\"'\n",
        "            )\n",
        "            \n",
        "            content = content.replace(\n",
        "                '\"directLink\": f\"https://mock.direct.link/{os.path.basename(file_path)}\"',\n",
        "                '\"directLink\": f\"https://drive.google.com/uc?id=mock_file_id&export=download\"'\n",
        "            )\n",
        "            \n",
        "            # Add warning logging\n",
        "            content = content.replace(\n",
        "                'logger.info(f\"Mock upload: {os.path.basename(file_path)}',\n",
        "                'logger.warning(f\"Google Drive service not initialized! Using mock upload for: {os.path.basename(file_path)}\")\n",
        "            logger.warning(\"Check Google Drive credentials and token.pickle file\")'\n",
        "            )\n",
        "            \n",
        "            with open(service_file, 'w', encoding='utf-8') as f:\n",
        "                f.write(content)\n",
        "            \n",
        "            print(\"âœ… Google Drive service fixed\")\n",
        "            return True\n",
        "        else:\n",
        "            print(\"âœ… No mock code found\")\n",
        "            return True\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error fixing service: {e}\")\n",
        "        return False\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    fix_google_drive_service()\n",
        "'''\n",
        "\n",
        "with open('/content/videobot/fix_google_drive.py', 'w') as f:\n",
        "    f.write(drive_fix_code)\n",
        "\n",
        "print(\"âœ… Google Drive fix script created\")\n",
        "\n",
        "# Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¸ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ\n",
        "!cd /content/videobot && python fix_google_drive.py\n",
        "\n",
        "print(\"\\nâœ… Enhanced monitoring tools ready!\")"
      ],
      "metadata": {
        "id": "create_monitoring_tools"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## âš™ï¸ Ð¨Ð°Ð³ 3: ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸\n",
        "\n",
        "ÐÐ°ÑÑ‚Ñ€Ð°Ð¸Ð²Ð°ÐµÐ¼ Ñ‚Ð¾ÐºÐµÐ½ Ð±Ð¾Ñ‚Ð° Ð¸ Ð´Ñ€ÑƒÐ³Ð¸Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹."
      ],
      "metadata": {
        "id": "step3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ\n",
        "import os\n",
        "\n",
        "# âš ï¸ ÐžÐ‘Ð¯Ð—ÐÐ¢Ð•Ð›Ð¬ÐÐž Ð—ÐÐœÐ•ÐÐ˜Ð¢Ð• ÐÐ Ð¡Ð’ÐžÐ˜ Ð—ÐÐÐ§Ð•ÐÐ˜Ð¯!\n",
        "TELEGRAM_BOT_TOKEN = \"7850144731:AAHeHudyAVljC2J_CR8NLZznqnDHu8ZgLUw\"  # Ð’Ð°Ñˆ Ñ‚Ð¾ÐºÐµÐ½\n",
        "TELEGRAM_ADMIN_IDS = \"1390176649\"   # Ð’Ð°Ñˆ Telegram ID\n",
        "\n",
        "# Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ .env Ñ„Ð°Ð¹Ð»\n",
        "env_content = f\"\"\"# Telegram Bot Configuration\n",
        "TELEGRAM_BOT_TOKEN={TELEGRAM_BOT_TOKEN}\n",
        "TELEGRAM_ADMIN_IDS={TELEGRAM_ADMIN_IDS}\n",
        "\n",
        "# Database Configuration\n",
        "DATABASE_URL=postgresql+asyncpg://postgres:videobot_password@localhost:5432/videobot\n",
        "\n",
        "# Redis Configuration\n",
        "REDIS_URL=redis://localhost:6379/0\n",
        "CELERY_BROKER_URL=redis://localhost:6379/1\n",
        "CELERY_RESULT_BACKEND=redis://localhost:6379/2\n",
        "\n",
        "# Application Configuration\n",
        "DEBUG=true\n",
        "LOG_LEVEL=INFO\n",
        "TEMP_DIR=/content/videobot/temp\n",
        "FONTS_DIR=/content/videobot/fonts\n",
        "\n",
        "# Video Processing Configuration\n",
        "MAX_VIDEO_DURATION=1800\n",
        "MAX_FILE_SIZE=1073741824\n",
        "FFMPEG_TIMEOUT=600\n",
        "\"\"\"\n",
        "\n",
        "with open('/content/videobot/.env', 'w') as f:\n",
        "    f.write(env_content)\n",
        "\n",
        "print(\"âœ… ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð°!\")\n",
        "print(f\"ðŸ¤– Bot Token: {TELEGRAM_BOT_TOKEN[:20]}...\")\n",
        "print(f\"ðŸ‘¤ Admin ID: {TELEGRAM_ADMIN_IDS}\")"
      ],
      "metadata": {
        "id": "configure"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸš€ Ð¨Ð°Ð³ 4: Ð—Ð°Ð¿ÑƒÑÐº Ð±Ð¾Ñ‚Ð°\n",
        "\n",
        "Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð²ÑÐµ ÑÐµÑ€Ð²Ð¸ÑÑ‹ Ð¸ ÑÐ°Ð¼ Ð±Ð¾Ñ‚."
      ],
      "metadata": {
        "id": "step4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð¸ Ð·Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ ÑÐµÑ€Ð²Ð¸ÑÑ‹\n",
        "import os\n",
        "import time\n",
        "\n",
        "print(\"ðŸ” Checking and starting services...\")\n",
        "\n",
        "# PostgreSQL\n",
        "pg_result = os.system(\"pg_isready -h localhost -p 5432 > /dev/null 2>&1\")\n",
        "if pg_result != 0:\n",
        "    print(\"ðŸ—„ï¸ Starting PostgreSQL...\")\n",
        "    os.system(\"service postgresql start\")\n",
        "    time.sleep(2)\n",
        "\n",
        "# Redis\n",
        "redis_result = os.system(\"redis-cli ping > /dev/null 2>&1\")\n",
        "if redis_result != 0:\n",
        "    print(\"ðŸ”´ Starting Redis...\")\n",
        "    os.system(\"service redis-server start\")\n",
        "    time.sleep(2)\n",
        "\n",
        "# Final check\n",
        "pg_status = \"âœ…\" if os.system(\"pg_isready -h localhost -p 5432 > /dev/null 2>&1\") == 0 else \"âŒ\"\n",
        "redis_status = \"âœ…\" if os.system(\"redis-cli ping > /dev/null 2>&1\") == 0 else \"âŒ\"\n",
        "\n",
        "print(f\"\\nðŸ“Š Services Status:\")\n",
        "print(f\"ðŸ—„ï¸ PostgreSQL: {pg_status}\")\n",
        "print(f\"ðŸ”´ Redis: {redis_status}\")\n",
        "\n",
        "if pg_status == \"âœ…\" and redis_status == \"âœ…\":\n",
        "    print(\"\\nâœ… All services ready!\")\n",
        "else:\n",
        "    print(\"\\nâŒ Some services failed to start!\")\n",
        "\n",
        "# Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ð±Ð°Ð·Ñƒ Ð´Ð°Ð½Ð½Ñ‹Ñ…\n",
        "print(\"\\nðŸ—„ï¸ Initializing database...\")\n",
        "os.chdir('/content/videobot')\n",
        "!python -c \"import asyncio; from app.database.connection import init_database; asyncio.run(init_database())\""
      ],
      "metadata": {
        "id": "start_services"
      },
      "execution_count": null,
      "outputs": []
    },

    {
      "cell_type": "code",
      "source": [
        "# Ð—Ð°Ð¿ÑƒÑÐº Ð¿Ð¾Ð»Ð½Ð¾Ð¹ Ð²ÐµÑ€ÑÐ¸Ð¸ Ð±Ð¾Ñ‚Ð°\n",
        "print(\"ðŸš€ Starting VideoGenerator3000 (Full Version)...\")\n",
        "\n",
        "# Change to project directory\n",
        "import os\n",
        "os.chdir('/content/videobot')\n",
        "\n",
        "# Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ðµ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ (Ð¿Ð¾Ð»Ð½Ð°Ñ Ð²ÐµÑ€ÑÐ¸Ñ Ñ Celery)\n",
        "!python -m app.main"
      ],
      "metadata": {
        "id": "run_bot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ÐÐ»ÑŒÑ‚ÐµÑ€Ð½Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ð·Ð°Ð¿ÑƒÑÐº ÐµÑÐ»Ð¸ Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ð½Ðµ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚\n",
        "print(\"ðŸ”„ Alternative startup method...\")\n",
        "\n",
        "# Ð•ÑÐ»Ð¸ app.main Ð½Ðµ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚, Ð¿Ñ€Ð¾Ð±ÑƒÐµÐ¼ run_bot.py\n",
        "import os\n",
        "os.chdir('/content/videobot')\n",
        "\n",
        "if os.path.exists('run_bot.py'):\n",
        "    print(\"ðŸ“‹ Using run_bot.py...\")\n",
        "    !python run_bot.py\n",
        "elif os.path.exists('app/main.py'):\n",
        "    print(\"ðŸ“‹ Using app/main.py directly...\")\n",
        "    !python app/main.py\n",
        "else:\n",
        "    print(\"âŒ No main entry point found!\")\n",
        "    print(\"Available Python files:\")\n",
        "    !find . -name \"*.py\" | grep -E \"(main|run|bot)\" | head -10"
      ],
      "metadata": {
        "id": "run_bot_alt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ”§ ÐŸÐ¾Ð»ÐµÐ·Ð½Ñ‹Ðµ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹ Ð´Ð»Ñ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð°\n",
        "\n",
        "Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ ÑÑ‚Ð¸ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ Ð±Ð¾Ñ‚Ð°."
      ],
      "metadata": {
        "id": "monitoring"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑÑ‚Ð°Ñ‚ÑƒÑÐ° ÑÐµÑ€Ð²Ð¸ÑÐ¾Ð²\n",
        "print(\"ðŸ” Checking services status...\")\n",
        "\n",
        "# PostgreSQL\n",
        "!pg_isready -h localhost -p 5432 && echo \"âœ… PostgreSQL: OK\" || echo \"âŒ PostgreSQL: Failed\"\n",
        "\n",
        "# Redis\n",
        "!redis-cli ping && echo \"âœ… Redis: OK\" || echo \"âŒ Redis: Failed\"\n",
        "\n",
        "# ÐŸÑ€Ð¾Ñ†ÐµÑÑÑ‹\n",
        "!ps aux | grep -E '(postgres|redis|celery|python)' | grep -v grep"
      ],
      "metadata": {
        "id": "check_services"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ÐŸÑ€Ð¾ÑÐ¼Ð¾Ñ‚Ñ€ Ð»Ð¾Ð³Ð¾Ð²\n",
        "!tail -n 50 /content/videobot/logs/bot.log"
      ],
      "metadata": {
        "id": "view_logs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ Ð´Ð¸ÑÐºÐ°\n",
        "!df -h /content\n",
        "!du -sh /content/videobot/temp/*"
      ],
      "metadata": {
        "id": "check_disk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ› ï¸ Ð£ÑÑ‚Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð½ÐµÐ¿Ð¾Ð»Ð°Ð´Ð¾Ðº\n",
        "\n",
        "Ð•ÑÐ»Ð¸ Ñ‡Ñ‚Ð¾-Ñ‚Ð¾ Ð¿Ð¾ÑˆÐ»Ð¾ Ð½Ðµ Ñ‚Ð°Ðº, Ð¿Ð¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ ÑÑ‚Ð¸ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹."
      ],
      "metadata": {
        "id": "troubleshooting"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ÐŸÐµÑ€ÐµÐ·Ð°Ð¿ÑƒÑÐº ÑÐµÑ€Ð²Ð¸ÑÐ¾Ð²\n",
        "!service postgresql restart\n",
        "!service redis-server restart\n",
        "\n",
        "# ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð²\n",
        "!rm -rf /content/videobot/temp/*\n",
        "\n",
        "# ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ‹Ñ… Ð¿Ð°ÐºÐµÑ‚Ð¾Ð²\n",
        "!pip list | grep -E '(aiogram|celery|redis|sqlalchemy)'"
      ],
      "metadata": {
        "id": "troubleshoot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ’¾ Ð ÐµÐ·ÐµÑ€Ð²Ð½Ð¾Ðµ ÐºÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ\n",
        "\n",
        "Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚Ðµ Ð²Ð°Ð¶Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¿ÐµÑ€ÐµÐ´ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸ÐµÐ¼ ÑÐµÑÑÐ¸Ð¸."
      ],
      "metadata": {
        "id": "backup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð°Ñ€Ñ…Ð¸Ð²Ð° Ñ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸\n",
        "!tar -czf /content/videobot_backup.tar.gz /content/videobot/\n",
        "\n",
        "# Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…\n",
        "!pg_dump -h localhost -U postgres videobot > /content/videobot_db_backup.sql\n",
        "\n",
        "print(\"ðŸ’¾ Backup files created:\")\n",
        "print(\"   - /content/videobot_backup.tar.gz\")\n",
        "print(\"   - /content/videobot_db_backup.sql\")\n",
        "print(\"\\nðŸ“¥ Download these files before session ends!\")"
      ],
      "metadata": {
        "id": "backup_data"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}