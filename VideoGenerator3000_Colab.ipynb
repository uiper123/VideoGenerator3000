{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üé¨ VideoGenerator3000 - Google Colab Edition\n",
        "\n",
        "–ü–æ–ª–Ω–∞—è –≤–µ—Ä—Å–∏—è Telegram –±–æ—Ç–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö, –æ—á–µ—Ä–µ–¥—è–º–∏ –∑–∞–¥–∞—á –∏ –≤—Å–µ–º–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏.\n",
        "\n",
        "## ‚ö†Ô∏è –í–∞–∂–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è Colab:\n",
        "- –°–µ—Å—Å–∏—è –∂–∏–≤–µ—Ç 12-24 —á–∞—Å–∞\n",
        "- –í—Å–µ –¥–∞–Ω–Ω—ã–µ —É–¥–∞–ª—è—é—Ç—Å—è –ø—Ä–∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–µ\n",
        "- –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã CPU/RAM\n",
        "- –ù–µ—Ç –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–≥–æ IP\n",
        "\n",
        "## üöÄ –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:\n",
        "- ‚úÖ –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ –≤ —Ñ–æ—Ä–º–∞—Ç Shorts (9:16)\n",
        "- ‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö PostgreSQL\n",
        "- ‚úÖ –û—á–µ—Ä–µ–¥–∏ –∑–∞–¥–∞—á Celery + Redis\n",
        "- ‚úÖ –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Å YouTube, TikTok –∏ –¥—Ä.\n",
        "- ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Å—É–±—Ç–∏—Ç—Ä—ã\n",
        "- ‚úÖ –†–∞–∑–º—ã—Ç—ã–π —Ñ–æ–Ω\n",
        "- ‚úÖ –ù–∞—Ä–µ–∑–∫–∞ –Ω–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã\n",
        "- ‚úÖ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Google Drive\n"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìã –®–∞–≥ 1: –°–∏—Å—Ç–µ–º–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞\n",
        "\n",
        "–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∏ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –æ–∫—Ä—É–∂–µ–Ω–∏–µ."
      ],
      "metadata": {
        "id": "step1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# –ö–ª–æ–Ω–∏—Ä—É–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —Å GitHub\n",
        "print(\"üì• Cloning repository from GitHub...\")\n",
        "!git clone https://github.com/uiper123/VideoGenerator3000.git /content/VideoGenerator3000\n",
        "\n",
        "# –ü–µ—Ä–µ—Ö–æ–¥–∏–º –≤ –ø–∞–ø–∫—É –ø—Ä–æ–µ–∫—Ç–∞\n",
        "%cd /content/VideoGenerator3000\n",
        "\n",
        "# –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Å–∫–∞—á–∞–ª–æ—Å—å\n",
        "print(\"\\nüìÅ Repository contents:\")\n",
        "!ls -la\n",
        "\n",
        "print(\"\\n‚úÖ Repository cloned successfully!\")"
      ],
      "metadata": {
        "id": "clone_repo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É\n",
        "print(\"üîß Running system setup...\")\n",
        "!python colab_setup_direct.py\n",
        "\n",
        "print(\"\\n‚úÖ System setup completed!\")"
      ],
      "metadata": {
        "id": "run_setup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìÅ –®–∞–≥ 2: –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–¥–∞ –±–æ—Ç–∞\n",
        "\n",
        "–ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞. –ï—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ø–æ—Å–æ–±–æ–≤:"
      ],
      "metadata": {
        "id": "step2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –∏–∑ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è –≤ —Ä–∞–±–æ—á—É—é –ø–∞–ø–∫—É\n",
        "print(\"üìÅ Setting up project files...\")\n",
        "\n",
        "# –ö–æ–ø–∏—Ä—É–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞ –≤ /content/videobot/\n",
        "!mkdir -p /content/videobot\n",
        "!cp -r /content/VideoGenerator3000/app /content/videobot/ 2>/dev/null || echo \"No app folder found\"\n",
        "!cp /content/VideoGenerator3000/*.py /content/videobot/ 2>/dev/null || echo \"No Python files in root\"\n",
        "!cp /content/VideoGenerator3000/requirements.txt /content/videobot/ 2>/dev/null || echo \"No requirements.txt\"\n",
        "!cp /content/VideoGenerator3000/.env /content/videobot/ 2>/dev/null || echo \"No .env file\"\n",
        "\n",
        "# –°–æ–∑–¥–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞–ø–∫–∏\n",
        "!mkdir -p /content/videobot/temp\n",
        "!mkdir -p /content/videobot/logs\n",
        "!mkdir -p /content/videobot/fonts\n",
        "\n",
        "print(\"\\nüìã Project structure:\")\n",
        "!ls -la /content/videobot/\n",
        "\n",
        "print(\"\\n‚úÖ Project files ready!\")"
      ],
      "metadata": {
        "id": "setup_project"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–æ–±–ª–µ–º—É —Å youtube_dl –≤ –∫–æ–¥–µ\n",
        "print(\"üîß Fixing youtube_dl imports...\")\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# –ù–∞–π–¥–µ–º –≤—Å–µ Python —Ñ–∞–π–ª—ã –≤ –ø—Ä–æ–µ–∫—Ç–µ\n",
        "python_files = glob.glob('/content/videobot/**/*.py', recursive=True)\n",
        "python_files.extend(glob.glob('/content/videobot/*.py'))\n",
        "\n",
        "fixed_files = []\n",
        "for file_path in python_files:\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "        \n",
        "        # –ï—Å–ª–∏ –µ—Å—Ç—å youtube_dl, –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ yt_dlp\n",
        "        if 'youtube_dl' in content:\n",
        "            print(f\"üîß Fixing {file_path}\")\n",
        "            content = content.replace('import youtube_dl', 'import yt_dlp as youtube_dl')\n",
        "            content = content.replace('from youtube_dl', 'from yt_dlp')\n",
        "            \n",
        "            with open(file_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(content)\n",
        "            fixed_files.append(file_path)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error processing {file_path}: {e}\")\n",
        "\n",
        "if fixed_files:\n",
        "    print(f\"\\n‚úÖ Fixed {len(fixed_files)} files:\")\n",
        "    for file in fixed_files:\n",
        "        print(f\"   - {file}\")\n",
        "else:\n",
        "    print(\"\\n‚úÖ No youtube_dl imports found to fix\")\n",
        "\n",
        "print(\"\\n‚úÖ Code fixes completed!\")"
      ],
      "metadata": {
        "id": "fix_imports"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# –°–æ–∑–¥–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏\n",
        "print(\"üîß Creating enhanced monitoring tools...\")\n",
        "\n",
        "# 1. Google Drive Checker\n",
        "drive_checker_code = '''#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Google Drive Token Checker - –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å —Ç–æ–∫–µ–Ω–∞ Google Drive\n",
        "\"\"\"\n",
        "import os\n",
        "import pickle\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "try:\n",
        "    from google.auth.transport.requests import Request\n",
        "    from google.oauth2.credentials import Credentials\n",
        "    from google_auth_oauthlib.flow import InstalledAppFlow\n",
        "    from googleapiclient.discovery import build\n",
        "    from googleapiclient.errors import HttpError\n",
        "    GOOGLE_LIBS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    GOOGLE_LIBS_AVAILABLE = False\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class GoogleDriveChecker:\n",
        "    \"\"\"–ö–ª–∞—Å—Å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ Google Drive —Ç–æ–∫–µ–Ω–∞ –∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è\"\"\"\n",
        "    \n",
        "    def __init__(self, token_path: str = \"token.pickle\", credentials_path: str = \"google-credentials.json\"):\n",
        "        self.token_path = token_path\n",
        "        self.credentials_path = credentials_path\n",
        "        self.scopes = ['https://www.googleapis.com/auth/drive']\n",
        "    \n",
        "    def check_libraries(self) -> dict:\n",
        "        \"\"\"–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫\"\"\"\n",
        "        result = {\n",
        "            'status': 'success' if GOOGLE_LIBS_AVAILABLE else 'error',\n",
        "            'message': 'Google libraries available' if GOOGLE_LIBS_AVAILABLE else 'Google libraries not installed',\n",
        "            'libraries': GOOGLE_LIBS_AVAILABLE\n",
        "        }\n",
        "        \n",
        "        if not GOOGLE_LIBS_AVAILABLE:\n",
        "            result['fix'] = 'pip install google-api-python-client google-auth-httplib2 google-auth-oauthlib'\n",
        "        \n",
        "        return result\n",
        "    \n",
        "    def check_credentials_file(self) -> dict:\n",
        "        \"\"\"–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞ credentials\"\"\"\n",
        "        if not os.path.exists(self.credentials_path):\n",
        "            return {\n",
        "                'status': 'error',\n",
        "                'message': f'Credentials file not found: {self.credentials_path}',\n",
        "                'fix': 'Download credentials.json from Google Cloud Console'\n",
        "            }\n",
        "        \n",
        "        try:\n",
        "            with open(self.credentials_path, 'r') as f:\n",
        "                import json\n",
        "                creds_data = json.load(f)\n",
        "                \n",
        "            if 'installed' in creds_data or 'web' in creds_data:\n",
        "                return {\n",
        "                    'status': 'success',\n",
        "                    'message': f'Credentials file found and valid: {self.credentials_path}',\n",
        "                    'type': 'installed' if 'installed' in creds_data else 'web'\n",
        "                }\n",
        "            else:\n",
        "                return {\n",
        "                    'status': 'error',\n",
        "                    'message': 'Invalid credentials file format',\n",
        "                    'fix': 'Re-download credentials.json from Google Cloud Console'\n",
        "                }\n",
        "                \n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'status': 'error',\n",
        "                'message': f'Error reading credentials file: {e}',\n",
        "                'fix': 'Check credentials.json file format'\n",
        "            }\n",
        "    \n",
        "    def check_token_file(self) -> dict:\n",
        "        \"\"\"–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∏ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å —Ç–æ–∫–µ–Ω–∞\"\"\"\n",
        "        if not os.path.exists(self.token_path):\n",
        "            return {\n",
        "                'status': 'warning',\n",
        "                'message': f'Token file not found: {self.token_path}',\n",
        "                'fix': 'Run OAuth flow to generate token'\n",
        "            }\n",
        "        \n",
        "        try:\n",
        "            with open(self.token_path, 'rb') as token:\n",
        "                creds = pickle.load(token)\n",
        "            \n",
        "            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–∑–æ–≤—ã–µ —Å–≤–æ–π—Å—Ç–≤–∞ —Ç–æ–∫–µ–Ω–∞\n",
        "            token_info = {\n",
        "                'status': 'success',\n",
        "                'message': f'Token file found: {self.token_path}',\n",
        "                'valid': creds.valid if hasattr(creds, 'valid') else False,\n",
        "                'expired': creds.expired if hasattr(creds, 'expired') else True,\n",
        "                'token_uri': getattr(creds, 'token_uri', 'N/A'),\n",
        "                'scopes': getattr(creds, 'scopes', [])\n",
        "            }\n",
        "            \n",
        "            if hasattr(creds, 'expiry') and creds.expiry:\n",
        "                token_info['expiry'] = creds.expiry.isoformat()\n",
        "                token_info['expires_in_hours'] = (creds.expiry - datetime.utcnow()).total_seconds() / 3600\n",
        "            \n",
        "            return token_info\n",
        "                \n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'status': 'error',\n",
        "                'message': f'Error reading token file: {e}',\n",
        "                'fix': 'Delete token.pickle and re-run OAuth flow'\n",
        "            }\n",
        "    \n",
        "    def test_drive_connection(self) -> dict:\n",
        "        \"\"\"–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Google Drive\"\"\"\n",
        "        if not GOOGLE_LIBS_AVAILABLE:\n",
        "            return {\n",
        "                'status': 'error',\n",
        "                'message': 'Google libraries not available',\n",
        "                'fix': 'Install required libraries first'\n",
        "            }\n",
        "        \n",
        "        try:\n",
        "            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω\n",
        "            creds = None\n",
        "            if os.path.exists(self.token_path):\n",
        "                with open(self.token_path, 'rb') as token:\n",
        "                    creds = pickle.load(token)\n",
        "            \n",
        "            # –ï—Å–ª–∏ —Ç–æ–∫–µ–Ω–∞ –Ω–µ—Ç –∏–ª–∏ –æ–Ω –Ω–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω, –ø—ã—Ç–∞–µ–º—Å—è –æ–±–Ω–æ–≤–∏—Ç—å\n",
        "            if not creds or not creds.valid:\n",
        "                if creds and creds.expired and creds.refresh_token:\n",
        "                    logger.info(\"Refreshing expired token...\")\n",
        "                    creds.refresh(Request())\n",
        "                else:\n",
        "                    return {\n",
        "                        'status': 'error',\n",
        "                        'message': 'No valid credentials available',\n",
        "                        'fix': 'Run OAuth flow to get new token'\n",
        "                    }\n",
        "            \n",
        "            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ\n",
        "            service = build('drive', 'v3', credentials=creds)\n",
        "            \n",
        "            # –ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è\n",
        "            results = service.files().list(pageSize=1, fields=\"files(id, name)\").execute()\n",
        "            files = results.get('files', [])\n",
        "            \n",
        "            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ\n",
        "            about = service.about().get(fields=\"user\").execute()\n",
        "            user_info = about.get('user', {})\n",
        "            \n",
        "            return {\n",
        "                'status': 'success',\n",
        "                'message': 'Google Drive connection successful',\n",
        "                'user_email': user_info.get('emailAddress', 'N/A'),\n",
        "                'user_name': user_info.get('displayName', 'N/A'),\n",
        "                'files_accessible': len(files) > 0,\n",
        "                'test_time': datetime.now().isoformat()\n",
        "            }\n",
        "                \n",
        "        except HttpError as e:\n",
        "            return {\n",
        "                'status': 'error',\n",
        "                'message': f'Google Drive API error: {e}',\n",
        "                'error_code': getattr(e, 'resp', {}).get('status', 'unknown'),\n",
        "                'fix': 'Check API permissions and quotas'\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'status': 'error',\n",
        "                'message': f'Connection test failed: {e}',\n",
        "                'fix': 'Check credentials and network connection'\n",
        "            }\n",
        "    \n",
        "    def full_check(self) -> dict:\n",
        "        \"\"\"–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É Google Drive –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏\"\"\"\n",
        "        logger.info(\"üîç Starting full Google Drive check...\")\n",
        "        \n",
        "        results = {\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "            'libraries': self.check_libraries(),\n",
        "            'credentials_file': self.check_credentials_file(),\n",
        "            'token_file': self.check_token_file(),\n",
        "            'drive_connection': None,\n",
        "            'overall_status': 'unknown'\n",
        "        }\n",
        "        \n",
        "        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ—à–ª–∏\n",
        "        if (results['libraries']['status'] == 'success' and \n",
        "            results['credentials_file']['status'] == 'success'):\n",
        "            results['drive_connection'] = self.test_drive_connection()\n",
        "        else:\n",
        "            results['drive_connection'] = {\n",
        "                'status': 'skipped',\n",
        "                'message': 'Skipped due to previous errors'\n",
        "            }\n",
        "        \n",
        "        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—â–∏–π —Å—Ç–∞—Ç—É—Å\n",
        "        if results['drive_connection']['status'] == 'success':\n",
        "            results['overall_status'] = 'success'\n",
        "        elif any(r['status'] == 'error' for r in results.values() if isinstance(r, dict)):\n",
        "            results['overall_status'] = 'error'\n",
        "        else:\n",
        "            results['overall_status'] = 'warning'\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def format_check_results(self, results: dict) -> str:\n",
        "        \"\"\"–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–ª—è –≤—ã–≤–æ–¥–∞\"\"\"\n",
        "        output = []\n",
        "        output.append(\"üîç Google Drive Integration Check\")\n",
        "        output.append(\"=\" * 40)\n",
        "        \n",
        "        # –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏\n",
        "        lib_status = \"‚úÖ\" if results['libraries']['status'] == 'success' else \"‚ùå\"\n",
        "        output.append(f\"{lib_status} Libraries: {results['libraries']['message']}\")\n",
        "        if 'fix' in results['libraries']:\n",
        "            output.append(f\"   Fix: {results['libraries']['fix']}\")\n",
        "        \n",
        "        # –§–∞–π–ª credentials\n",
        "        cred_status = \"‚úÖ\" if results['credentials_file']['status'] == 'success' else \"‚ùå\"\n",
        "        output.append(f\"{cred_status} Credentials: {results['credentials_file']['message']}\")\n",
        "        if 'fix' in results['credentials_file']:\n",
        "            output.append(f\"   Fix: {results['credentials_file']['fix']}\")\n",
        "        \n",
        "        # –¢–æ–∫–µ–Ω\n",
        "        token_status = \"‚úÖ\" if results['token_file']['status'] == 'success' else (\"‚ö†Ô∏è\" if results['token_file']['status'] == 'warning' else \"‚ùå\")\n",
        "        output.append(f\"{token_status} Token: {results['token_file']['message']}\")\n",
        "        if 'valid' in results['token_file']:\n",
        "            output.append(f\"   Valid: {results['token_file']['valid']}\")\n",
        "            output.append(f\"   Expired: {results['token_file']['expired']}\")\n",
        "        if 'expires_in_hours' in results['token_file']:\n",
        "            hours = results['token_file']['expires_in_hours']\n",
        "            if hours > 0:\n",
        "                output.append(f\"   Expires in: {hours:.1f} hours\")\n",
        "            else:\n",
        "                output.append(f\"   Expired {abs(hours):.1f} hours ago\")\n",
        "        \n",
        "        # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Drive\n",
        "        if results['drive_connection']['status'] != 'skipped':\n",
        "            drive_status = \"‚úÖ\" if results['drive_connection']['status'] == 'success' else \"‚ùå\"\n",
        "            output.append(f\"{drive_status} Drive Connection: {results['drive_connection']['message']}\")\n",
        "            if 'user_email' in results['drive_connection']:\n",
        "                output.append(f\"   User: {results['drive_connection']['user_email']}\")\n",
        "            if 'fix' in results['drive_connection']:\n",
        "                output.append(f\"   Fix: {results['drive_connection']['fix']}\")\n",
        "        \n",
        "        # –û–±—â–∏–π —Å—Ç–∞—Ç—É—Å\n",
        "        overall_emoji = {\"success\": \"‚úÖ\", \"warning\": \"‚ö†Ô∏è\", \"error\": \"‚ùå\"}.get(results['overall_status'], \"‚ùì\")\n",
        "        output.append(f\"\\n{overall_emoji} Overall Status: {results['overall_status'].upper()}\")\n",
        "        \n",
        "        return \"\\n\".join(output)\n",
        "'''\n",
        "\n",
        "with open('/content/videobot/google_drive_checker.py', 'w') as f:\n",
        "    f.write(drive_checker_code)\n",
        "\n",
        "print(\"‚úÖ Google Drive checker created\")\n",
        "\n",
        "# 2. Enhanced Worker Logger\n",
        "worker_logger_code = '''#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Enhanced Worker Logger - –¥–æ–±–∞–≤–ª—è–µ—Ç –¥–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ Celery tasks\n",
        "\"\"\"\n",
        "import os\n",
        "import logging\n",
        "import sys\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "def get_worker_logs(lines: int = 50) -> str:\n",
        "    \"\"\"–ü–æ–ª—É—á–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ –ª–æ–≥–∏ worker'–æ–≤\"\"\"\n",
        "    try:\n",
        "        log_file = Path(\"logs/worker.log\")\n",
        "        if not log_file.exists():\n",
        "            return \"‚ùå –§–∞–π–ª –ª–æ–≥–æ–≤ worker'–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω\"\n",
        "        \n",
        "        with open(log_file, 'r', encoding='utf-8') as f:\n",
        "            all_lines = f.readlines()\n",
        "            recent_lines = all_lines[-lines:] if len(all_lines) > lines else all_lines\n",
        "            \n",
        "        return ''.join(recent_lines)\n",
        "    \n",
        "    except Exception as e:\n",
        "        return f\"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –ª–æ–≥–æ–≤: {e}\"\n",
        "'''\n",
        "\n",
        "with open('/content/videobot/enhanced_worker_logger.py', 'w') as f:\n",
        "    f.write(worker_logger_code)\n",
        "\n",
        "print(\"‚úÖ Enhanced worker logger created\")\n",
        "\n",
        "# 3. Google Drive Fix Script\n",
        "drive_fix_code = '''#!/usr/bin/env python3\n",
        "import os\n",
        "import pickle\n",
        "import logging\n",
        "\n",
        "def fix_google_drive_service():\n",
        "    \"\"\"–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç GoogleDriveService —á—Ç–æ–±—ã –æ–Ω –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª mock\"\"\"\n",
        "    print(\"üîß Fixing Google Drive service...\")\n",
        "    \n",
        "    service_file = \"app/services/google_drive.py\"\n",
        "    \n",
        "    if not os.path.exists(service_file):\n",
        "        print(f\"‚ùå File {service_file} not found\")\n",
        "        return False\n",
        "    \n",
        "    try:\n",
        "        with open(service_file, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "        \n",
        "        # Replace mock URLs with more informative ones\n",
        "        if \"mock.drive.url\" in content:\n",
        "            print(\"‚ö†Ô∏è Found mock code, fixing...\")\n",
        "            \n",
        "            content = content.replace(\n",
        "                '\"webViewLink\": \"https://mock.drive.url/file/view\"',\n",
        "                '\"webViewLink\": \"https://drive.google.com/file/d/mock_file_id/view\"'\n",
        "            )\n",
        "            \n",
        "            content = content.replace(\n",
        "                '\"directLink\": f\"https://mock.direct.link/{os.path.basename(file_path)}\"',\n",
        "                '\"directLink\": f\"https://drive.google.com/uc?id=mock_file_id&export=download\"'\n",
        "            )\n",
        "            \n",
        "            # Add warning logging\n",
        "            content = content.replace(\n",
        "                'logger.info(f\"Mock upload: {os.path.basename(file_path)}',\n",
        "                'logger.warning(f\"Google Drive service not initialized! Using mock upload for: {os.path.basename(file_path)}\")\n",
        "            logger.warning(\"Check Google Drive credentials and token.pickle file\")'\n",
        "            )\n",
        "            \n",
        "            with open(service_file, 'w', encoding='utf-8') as f:\n",
        "                f.write(content)\n",
        "            \n",
        "            print(\"‚úÖ Google Drive service fixed\")\n",
        "            return True\n",
        "        else:\n",
        "            print(\"‚úÖ No mock code found\")\n",
        "            return True\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error fixing service: {e}\")\n",
        "        return False\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    fix_google_drive_service()\n",
        "'''\n",
        "\n",
        "with open('/content/videobot/fix_google_drive.py', 'w') as f:\n",
        "    f.write(drive_fix_code)\n",
        "\n",
        "print(\"‚úÖ Google Drive fix script created\")\n",
        "\n",
        "# –ó–∞–ø—É—Å–∫–∞–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ\n",
        "!cd /content/videobot && python fix_google_drive.py\n",
        "\n",
        "print(\"\\n‚úÖ Enhanced monitoring tools ready!\")"
      ],
      "metadata": {
        "id": "create_monitoring_tools"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚öôÔ∏è –®–∞–≥ 3: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏\n",
        "\n",
        "–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Ç–æ–∫–µ–Ω –±–æ—Ç–∞ –∏ –¥—Ä—É–≥–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã."
      ],
      "metadata": {
        "id": "step3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è\n",
        "import os\n",
        "\n",
        "# ‚ö†Ô∏è –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ó–ê–ú–ï–ù–ò–¢–ï –ù–ê –°–í–û–ò –ó–ù–ê–ß–ï–ù–ò–Ø!\n",
        "TELEGRAM_BOT_TOKEN = \"7850144731:AAHeHudyAVljC2J_CR8NLZznqnDHu8ZgLUw\"  # –í–∞—à —Ç–æ–∫–µ–Ω\n",
        "TELEGRAM_ADMIN_IDS = \"1390176649\"   # –í–∞—à Telegram ID\n",
        "\n",
        "# –°–æ–∑–¥–∞–µ–º .env —Ñ–∞–π–ª\n",
        "env_content = f\"\"\"# Telegram Bot Configuration\n",
        "TELEGRAM_BOT_TOKEN={TELEGRAM_BOT_TOKEN}\n",
        "TELEGRAM_ADMIN_IDS={TELEGRAM_ADMIN_IDS}\n",
        "\n",
        "# Database Configuration\n",
        "DATABASE_URL=postgresql+asyncpg://postgres:videobot_password@localhost:5432/videobot\n",
        "\n",
        "# Redis Configuration\n",
        "REDIS_URL=redis://localhost:6379/0\n",
        "CELERY_BROKER_URL=redis://localhost:6379/1\n",
        "CELERY_RESULT_BACKEND=redis://localhost:6379/2\n",
        "\n",
        "# Application Configuration\n",
        "DEBUG=true\n",
        "LOG_LEVEL=INFO\n",
        "TEMP_DIR=/content/videobot/temp\n",
        "FONTS_DIR=/content/videobot/fonts\n",
        "\n",
        "# Video Processing Configuration\n",
        "MAX_VIDEO_DURATION=1800\n",
        "MAX_FILE_SIZE=1073741824\n",
        "FFMPEG_TIMEOUT=600\n",
        "\"\"\"\n",
        "\n",
        "with open('/content/videobot/.env', 'w') as f:\n",
        "    f.write(env_content)\n",
        "\n",
        "print(\"‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞!\")\n",
        "print(f\"ü§ñ Bot Token: {TELEGRAM_BOT_TOKEN[:20]}...\")\n",
        "print(f\"üë§ Admin ID: {TELEGRAM_ADMIN_IDS}\")"
      ],
      "metadata": {
        "id": "configure"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üöÄ –®–∞–≥ 4: –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞\n",
        "\n",
        "–ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ —Å–µ—Ä–≤–∏—Å—ã –∏ —Å–∞–º –±–æ—Ç."
      ],
      "metadata": {
        "id": "step4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º —Å–µ—Ä–≤–∏—Å—ã\n",
        "import os\n",
        "import time\n",
        "\n",
        "print(\"üîç Checking and starting services...\")\n",
        "\n",
        "# PostgreSQL\n",
        "pg_result = os.system(\"pg_isready -h localhost -p 5432 > /dev/null 2>&1\")\n",
        "if pg_result != 0:\n",
        "    print(\"üóÑÔ∏è Starting PostgreSQL...\")\n",
        "    os.system(\"service postgresql start\")\n",
        "    time.sleep(2)\n",
        "\n",
        "# Redis\n",
        "redis_result = os.system(\"redis-cli ping > /dev/null 2>&1\")\n",
        "if redis_result != 0:\n",
        "    print(\"üî¥ Starting Redis...\")\n",
        "    os.system(\"service redis-server start\")\n",
        "    time.sleep(2)\n",
        "\n",
        "# Final check\n",
        "pg_status = \"‚úÖ\" if os.system(\"pg_isready -h localhost -p 5432 > /dev/null 2>&1\") == 0 else \"‚ùå\"\n",
        "redis_status = \"‚úÖ\" if os.system(\"redis-cli ping > /dev/null 2>&1\") == 0 else \"‚ùå\"\n",
        "\n",
        "print(f\"\\nüìä Services Status:\")\n",
        "print(f\"üóÑÔ∏è PostgreSQL: {pg_status}\")\n",
        "print(f\"üî¥ Redis: {redis_status}\")\n",
        "\n",
        "if pg_status == \"‚úÖ\" and redis_status == \"‚úÖ\":\n",
        "    print(\"\\n‚úÖ All services ready!\")\n",
        "else:\n",
        "    print(\"\\n‚ùå Some services failed to start!\")\n",
        "\n",
        "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö\n",
        "print(\"\\nüóÑÔ∏è Initializing database...\")\n",
        "os.chdir('/content/videobot')\n",
        "!python -c \"import asyncio; from app.database.connection import init_database; asyncio.run(init_database())\""
      ],
      "metadata": {
        "id": "start_services"
      },
      "execution_count": null,
      "outputs": []
    },

    {
      "cell_type": "code",
      "source": [
        "# –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–π –≤–µ—Ä—Å–∏–∏ –±–æ—Ç–∞\n",
        "print(\"üöÄ Starting VideoGenerator3000 (Full Version)...\")\n",
        "\n",
        "# Change to project directory\n",
        "import os\n",
        "os.chdir('/content/videobot')\n",
        "\n",
        "# –ó–∞–ø—É—Å–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ (–ø–æ–ª–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å Celery)\n",
        "!python -m app.main"
      ],
      "metadata": {
        "id": "run_bot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –∑–∞–ø—É—Å–∫ –µ—Å–ª–∏ –æ—Å–Ω–æ–≤–Ω–æ–π –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç\n",
        "print(\"üîÑ Alternative startup method...\")\n",
        "\n",
        "# –ï—Å–ª–∏ app.main –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –ø—Ä–æ–±—É–µ–º run_bot.py\n",
        "import os\n",
        "os.chdir('/content/videobot')\n",
        "\n",
        "if os.path.exists('run_bot.py'):\n",
        "    print(\"üìã Using run_bot.py...\")\n",
        "    !python run_bot.py\n",
        "elif os.path.exists('app/main.py'):\n",
        "    print(\"üìã Using app/main.py directly...\")\n",
        "    !python app/main.py\n",
        "else:\n",
        "    print(\"‚ùå No main entry point found!\")\n",
        "    print(\"Available Python files:\")\n",
        "    !find . -name \"*.py\" | grep -E \"(main|run|bot)\" | head -10"
      ],
      "metadata": {
        "id": "run_bot_alt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîß –ü–æ–ª–µ–∑–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞\n",
        "\n",
        "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —ç—Ç–∏ –∫–æ–º–∞–Ω–¥—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è –±–æ—Ç–∞."
      ],
      "metadata": {
        "id": "monitoring"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ —Å–µ—Ä–≤–∏—Å–æ–≤\n",
        "print(\"üîç Checking services status...\")\n",
        "\n",
        "# PostgreSQL\n",
        "!pg_isready -h localhost -p 5432 && echo \"‚úÖ PostgreSQL: OK\" || echo \"‚ùå PostgreSQL: Failed\"\n",
        "\n",
        "# Redis\n",
        "!redis-cli ping && echo \"‚úÖ Redis: OK\" || echo \"‚ùå Redis: Failed\"\n",
        "\n",
        "# –ü—Ä–æ—Ü–µ—Å—Å—ã\n",
        "!ps aux | grep -E '(postgres|redis|celery|python)' | grep -v grep"
      ],
      "metadata": {
        "id": "check_services"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# –ü—Ä–æ—Å–º–æ—Ç—Ä –ª–æ–≥–æ–≤\n",
        "!tail -n 50 /content/videobot/logs/bot.log"
      ],
      "metadata": {
        "id": "view_logs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –¥–∏—Å–∫–∞\n",
        "!df -h /content\n",
        "!du -sh /content/videobot/temp/*"
      ],
      "metadata": {
        "id": "check_disk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üõ†Ô∏è –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–ø–æ–ª–∞–¥–æ–∫\n",
        "\n",
        "–ï—Å–ª–∏ —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —ç—Ç–∏ –∫–æ–º–∞–Ω–¥—ã."
      ],
      "metadata": {
        "id": "troubleshooting"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ —Å–µ—Ä–≤–∏—Å–æ–≤\n",
        "!service postgresql restart\n",
        "!service redis-server restart\n",
        "\n",
        "# –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤\n",
        "!rm -rf /content/videobot/temp/*\n",
        "\n",
        "# –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤\n",
        "!pip list | grep -E '(aiogram|celery|redis|sqlalchemy)'"
      ],
      "metadata": {
        "id": "troubleshoot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üíæ –†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
        "\n",
        "–°–æ—Ö—Ä–∞–Ω–∏—Ç–µ –≤–∞–∂–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ–º —Å–µ—Å—Å–∏–∏."
      ],
      "metadata": {
        "id": "backup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# –°–æ–∑–¥–∞–Ω–∏–µ –∞—Ä—Ö–∏–≤–∞ —Å –¥–∞–Ω–Ω—ã–º–∏\n",
        "!tar -czf /content/videobot_backup.tar.gz /content/videobot/\n",
        "\n",
        "# –≠–∫—Å–ø–æ—Ä—Ç –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö\n",
        "!pg_dump -h localhost -U postgres videobot > /content/videobot_db_backup.sql\n",
        "\n",
        "print(\"üíæ Backup files created:\")\n",
        "print(\"   - /content/videobot_backup.tar.gz\")\n",
        "print(\"   - /content/videobot_db_backup.sql\")\n",
        "print(\"\\nüì• Download these files before session ends!\")"
      ],
      "metadata": {
        "id": "backup_data"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}